# -*- coding: utf-8 -*-
"""CombinedCode_RF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GDEni5PqwlE2StxQgXRvD7VQXusifYme
"""

# copy from NN
#!pip install pythainlp
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib as mpl
#print(mpl.__version__)
import matplotlib.pyplot as plt
#!wget -q https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf
mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf')
mpl.rc('font', family='TH Sarabun New', size=12)
import seaborn as sns # สำหรับการพลอตกราฟ Confusion Matrix ที่สวยงาม
from sklearn.utils import class_weight
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.models import Sequential
from transformers import AutoTokenizer, AutoModel
import torch
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, chi2

# for RF
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import StratifiedKFold
from sklearn.utils.class_weight import compute_class_weight
import re
from pythainlp.tokenize import word_tokenize
from pythainlp.corpus.common import thai_stopwords
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
import joblib

df=pd.read_csv('trial.csv')
df.head()

thai_stopwords_set = set(thai_stopwords())

def remove_emojis_and_symbols(text):
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"  # Emoticons
        u"\U0001F300-\U0001F5FF"  # Symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # Transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # Flags
        u"\U00002700-\U000027BF"  # Dingbats
        u"\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE)
    text = emoji_pattern.sub(r'', text)
    text = re.sub(r"[^\u0E00-\u0E7Fa-zA-Z0-9\s]", "", text)
    return text

def clean_text_combined(text):
    if isinstance(text, str):
        text = remove_emojis_and_symbols(text)
        tokens = word_tokenize(text, engine='newmm')
        seen = set()
        unique_tokens = [token for token in tokens if not (token in seen or seen.add(token))]
        filtered_tokens = [token for token in unique_tokens if token not in thai_stopwords_set and token.strip()]
        return " ".join(filtered_tokens)
    else:
        return text

loaded_model = joblib.load('final_model_rf.pkl')
loaded_vectorizer = joblib.load('vectorizer_rf.pkl')
loaded_encoder = joblib.load('label_encoder_rf.pkl')
loaded_selector = joblib.load('selector_rf.pkl')

cleaned_new_texts = [clean_text_combined(text) for text in df.iloc[:,0]]
vect_new_texts = loaded_vectorizer.transform(cleaned_new_texts)
selected_features_new_texts = loaded_selector.transform(vect_new_texts) # Apply selector

# Make predictions
new_predictions_probs = loaded_model.predict(selected_features_new_texts)
#new_predictions_classes = np.argmax(new_predictions_probs, axis=1)

# Decode predictions back to original labels
decoded_predictions = loaded_encoder.inverse_transform(new_predictions_probs)

"""
for original_text, predicted_label in zip(df['text_column'], decoded_predictions):
    print(f"Original Text: '{original_text}' -> Predicted Label: '{predicted_label}'")

"""

results_df = pd.DataFrame({
    'original_text': df.iloc[:,0],
    'predicted_label': decoded_predictions
})

display(results_df)